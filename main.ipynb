{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a154006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Nov 22 21:08:38 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   57C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install -q google-generativeai pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85153934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import google.generativeai as genai\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "# Configure Gemini API\n",
    "GOOGLE_API_KEY = \"AIzaSyC7G9LAbM4eXHv2xhdu3NGN_DacRFuSmlA\"\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# Set up paths\n",
    "input_dir = Path(\"/workspaces/colab_test/pictures/input\")\n",
    "output_dir = Path(\"/workspaces/colab_test/pictures/output\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Initialize Gemini model\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")\n",
    "print(f\"Input directory: {input_dir}\")\n",
    "print(f\"Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba214c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_caption(image_path):\n",
    "    \"\"\"Generate a caption for an image using Gemini Vision API.\"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        \n",
    "        prompt = \"\"\"Analyze this image and create a detailed caption for LoRA training. \n",
    "        Start the caption with \"livapetersen\" followed by a comma, then describe:\n",
    "        - The person's appearance, pose, and expression\n",
    "        - Clothing and styling details\n",
    "        - Background and setting\n",
    "        - Lighting and mood\n",
    "        - Any notable features\n",
    "        \n",
    "        Format: livapetersen, [detailed description]\n",
    "        Keep it concise but descriptive (1-2 sentences).\"\"\"\n",
    "        \n",
    "        response = model.generate_content([prompt, img])\n",
    "        caption = response.text.strip()\n",
    "        \n",
    "        # Ensure caption starts with \"livapetersen\"\n",
    "        if not caption.lower().startswith(\"livapetersen\"):\n",
    "            caption = f\"livapetersen, {caption}\"\n",
    "        \n",
    "        return caption\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "print(\"‚úÖ Caption generation function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f735db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all images and generate captions\n",
    "image_files = sorted([f for f in input_dir.glob(\"*.jpeg\") if f.is_file()])\n",
    "print(f\"Found {len(image_files)} images to process\\n\")\n",
    "\n",
    "processed_files = []\n",
    "\n",
    "for idx, image_path in enumerate(image_files, 1):\n",
    "    print(f\"Processing {idx}/{len(image_files)}: {image_path.name}\")\n",
    "    \n",
    "    # Generate caption\n",
    "    caption = generate_caption(image_path)\n",
    "    \n",
    "    if caption:\n",
    "        # Create matching .txt file with same base name\n",
    "        txt_filename = image_path.stem + \".txt\"  # e.g., livapetersen_0001.txt\n",
    "        txt_path = output_dir / txt_filename\n",
    "        \n",
    "        # Write caption to file\n",
    "        with open(txt_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(caption)\n",
    "        \n",
    "        processed_files.append(txt_path)\n",
    "        print(f\"‚úÖ Created: {txt_filename}\")\n",
    "        print(f\"   Caption: {caption[:80]}...\")\n",
    "    else:\n",
    "        print(f\"‚ùå Failed to process {image_path.name}\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Small delay to avoid rate limiting\n",
    "    time.sleep(1)\n",
    "\n",
    "print(f\"\\n‚úÖ Processed {len(processed_files)}/{len(image_files)} images successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c946b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a zip file with all the caption files\n",
    "zip_path = Path(\"/workspaces/colab_test/livapetersen_captions.zip\")\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for txt_file in sorted(output_dir.glob(\"*.txt\")):\n",
    "        # Add file to zip with just the filename (no path)\n",
    "        zipf.write(txt_file, txt_file.name)\n",
    "        print(f\"Added to zip: {txt_file.name}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Created zip file: {zip_path}\")\n",
    "print(f\"üì¶ Zip contains {len(list(output_dir.glob('*.txt')))} caption files\")\n",
    "print(f\"\\nYou can download it from: {zip_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
